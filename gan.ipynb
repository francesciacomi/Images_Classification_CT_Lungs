{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"###Import libraries","metadata":{"id":"kfe1y4UedMd5"}},{"cell_type":"code","source":"!pip install -U tensorflow==2.9.2\n!apt install --allow-change-held-packages -y libcudnn8=8.1.0.77-1+cuda11.2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom PIL import Image\nfrom keras.applications.xception import preprocess_input\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"id":"TxZKtDIMc18q","outputId":"18289f9e-4c43-4d09-e1ba-3cd9a4259bf4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set seed for reproducibility","metadata":{"id":"pLb-N5JzUUQS"}},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"id":"C7HYua8HUHIj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Suppress warnings","metadata":{"id":"BDM82PpE3VSg"}},{"cell_type":"code","source":"import warnings\nimport logging\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\ntf.get_logger().setLevel('INFO')\ntf.autograph.set_verbosity(0)\n\ntf.get_logger().setLevel(logging.ERROR)\ntf.get_logger().setLevel('ERROR')\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","metadata":{"id":"5fXtacjAqOIq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Load data\nLoad the dataset to be used for classification","metadata":{"id":"pKlzZszgzl9g"}},{"cell_type":"code","source":"# Load the dataset by correctly specifying the right folder where it is stored and its name\ndataset_dir = '/kaggle/input/datasetaib/Dataset'\ntraining_dir = os.path.join(dataset_dir, 'train')\nvalidation_dir = os.path.join(dataset_dir, 'val')\ntest_dir = os.path.join(dataset_dir, 'test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tubercolosi_dir= '/kaggle/input/tubercolosi/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\naug_generator = ImageDataGenerator()w","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=ImageDataGenerator(rescale=1/255.\n                                         ).flow_from_directory(directory=tubercolosi_dir,\n                                                        target_size=(256,256),\n                                                        color_mode='rgb',\n                                                        classes=None,\n                                                        class_mode='categorical',\n                                                        batch_size=8,\n                                                        shuffle=True,\n                                                        seed=seed)\nY=X.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_generators(directory, bs, aug_gen):\n\n  generators = {}\n  training_dir = os.path.join(directory, 'train') \n  validation_dir = os.path.join(directory, 'val') \n  test_dir = os.path.join(directory, 'test') \n\n  generators['train'] = ImageDataGenerator(rescale=1/255.\n                                         ).flow_from_directory(directory=training_dir,\n                                                        target_size=(256,256),\n                                                        color_mode='rgb',\n                                                        classes=None,\n                                                        class_mode='categorical',\n                                                        batch_size=bs,\n                                                        shuffle=True,\n                                                        seed=seed)\n\n\n  # VALIDATION SET\n  generators['val'] = ImageDataGenerator(rescale=1/255.\n                                         ).flow_from_directory(directory=validation_dir,\n                                                target_size=(256,256),\n                                                color_mode='rgb',\n                                                classes=None,\n                                                class_mode='categorical',\n                                                batch_size=bs,\n                                                shuffle=False,\n                                                seed=seed)\n\n  # TEST SET\n  generators['test'] = ImageDataGenerator(rescale=1/255.\n                                          ).flow_from_directory(directory=test_dir,\n                                                target_size=(256,256),\n                                                color_mode='rgb',\n                                                classes=None,\n                                                class_mode='categorical',\n                                                batch_size=bs,\n                                                shuffle=False,\n                                                seed=seed)\n\n  return generators","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (256, 256, 3)\noutput_dim = 3\nepochs = 100\nmtrcs = ['accuracy']\nmonmtr = 'val_accuracy'\nbs = 32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model_name, test_set, target):\n  model = tfk.models.load_model(model_name)\n  predictions = model.predict(test_set)\n  metrics= {\n    \"model\": model_name,\n    \"predictions\" : predictions,\n    \"target\": target,\n    \"cm\": confusion_matrix(np.argmax(target, axis=-1), np.argmax(predictions, axis=-1), normalize='true', ),\n    \"accuracy\" : accuracy_score(np.argmax(target, axis=-1), np.argmax(predictions, axis=-1)),\n    \"precision\" : precision_score(np.argmax(target, axis=-1), np.argmax(predictions, axis=-1), average='macro'),\n    \"recall\" : recall_score(np.argmax(target, axis=-1), np.argmax(predictions, axis=-1), average='macro'),\n    \"f1\" : f1_score(np.argmax(target, axis=-1), np.argmax(predictions, axis=-1), average='macro')  }\n  \n  print(\"Model: \"+ str(metrics[\"model\"]))\n  print(\"Accuracy: \"+ str(metrics[\"accuracy\"]))\n  print(\"F1 score: \"+ str(metrics[\"f1\"]))\n  cm = metrics[\"cm\"]\n  plt.figure(figsize=(10,8))\n  sns.heatmap(cm.T, annot=True, fmt='.2f', xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n  plt.xlabel('True labels')\n  plt.ylabel('Predicted labels')\n  plt.show()\n\n  return metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gens = define_generators(dataset_dir, bs, aug_generator)\n\ntrain_gen = gens['train']\nvalid_gen = gens['val']\ntest_gen = gens['test']\n\ntrain_target = train_gen.classes\nval_target = valid_gen.classes\ntest_target = test_gen.classes\n\ntrain_target_cat = tfk.utils.to_categorical(train_gen.classes)\nval_target_cat = tfk.utils.to_categorical(valid_gen.classes) \ntest_target_cat = tfk.utils.to_categorical(test_gen.classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= train_gen\nY= train_target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install visualkeras\nimport visualkeras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = Y.max() +1 \nimage_size = input_shape[0]\nnum_channels = input_shape[-1]\nnum_classes,image_size,num_channels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_dim = 128\n\ndef get_dc_generator(input_shape, seed=seed):\n    tf.random.set_seed(seed)\n\n    # Build the generator layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    x = tfkl.Dense(4*4*64, use_bias=False, name='dense0')(input_layer)\n    x = tfkl.BatchNormalization(name='bn0')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation0')(x)\n    x = tfkl.Reshape((4,4,64))(x)\n\n    x = tfkl.UpSampling2D(name='upsampling1')(x)\n    x = tfkl.Conv2D(64, 3, padding='same', use_bias=False, name='conv1')(x)\n    x = tfkl.BatchNormalization(name='bn1')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation1')(x)\n    \n    x = tfkl.Conv2D(64, 3, padding='same', use_bias=False, name='conv1_2')(x)\n    x = tfkl.BatchNormalization(name='bn1_2')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation1_2')(x)\n\n    x = tfkl.UpSampling2D(name='upsampling2')(x)\n    x = tfkl.Conv2D(128, 3, padding='same', use_bias=False, name='conv2')(x)\n    x = tfkl.BatchNormalization(name='bn2')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation2')(x)\n\n    x = tfkl.Conv2D(128, 3, padding='same', use_bias=False, name='conv2_2')(x)\n    x = tfkl.BatchNormalization(name='bn2_2')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation2_2')(x)\n\n    x = tfkl.UpSampling2D(name='upsampling3')(x)\n    x = tfkl.Conv2D(256, 3, padding='same', use_bias=False, name='conv3')(x)\n    x = tfkl.BatchNormalization(name='bn3')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation3')(x)\n\n    x = tfkl.UpSampling2D(name='upsampling4')(x)\n    x = tfkl.Conv2D(1024, 3, padding='same', use_bias=False, name='conv4')(x)\n    x = tfkl.BatchNormalization(name='bn4')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation4')(x)\n\n    x = tfkl.UpSampling2D(name='upsampling5')(x)\n    x = tfkl.Conv2D(1024, 3, padding='same', use_bias=False, name='conv5')(x)\n    x = tfkl.BatchNormalization(name='bn5')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation5')(x)\n    \n    x = tfkl.UpSampling2D(name='upsampling6')(x)\n    x = tfkl.Conv2D(256, 3, padding='same', use_bias=False, name='conv6')(x)\n    x = tfkl.BatchNormalization(name='bn6')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation6')(x)\n    \n    \n    x = tfkl.Conv2D(3, 3, padding='same', use_bias=False, name='conv_out')(x)\n    output_layer = tfkl.Activation('tanh', name='activation_out')(x)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='generator')\n\n    # Return the model\n    return model\ngenerator = get_dc_generator(latent_dim)\ngenerator.summary()\ndisplay(visualkeras.layered_view(generator, legend=True, scale_xy=6))\ntfk.utils.plot_model(generator, show_shapes=True, expand_nested=True, to_file='vanilla_generator.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dc_discriminator(input_shape, seed=seed):\n    tf.random.set_seed(seed)\n\n    # Build the discriminator layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n    x = tfkl.ZeroPadding2D((2,2), name='padding')(input_layer)    #Zero padding to have the same shape of the input\n\n#Classical way to create a convolutional layer is to have a Convolutional layer, batch normalization and the activation function\n    x = tfkl.Conv2D(64, 3, padding='same', strides=2, name='conv1')(x)\n    x = tfkl.BatchNormalization(name='bn1')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation1')(x)\n\n    x = tfkl.Conv2D(128, 3, padding='same', strides=2, name='conv2')(x)\n    x = tfkl.BatchNormalization(name='bn2')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation2')(x)\n\n    x = tfkl.Conv2D(256, 3, padding='same', strides=2, name='conv3')(x)\n    x = tfkl.BatchNormalization(name='bn3')(x)\n    x = tfkl.LeakyReLU(alpha=0.2, name='activation3')(x)\n\n    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n    x = tfkl.Dropout(.5, seed=seed, name='dropout')(x)\n    x = tfkl.Dense(1, name='dense_out')(x)\n    output_layer = tfkl.Activation('sigmoid', name='output_layer')(x)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='discriminator')\n\n    # Return the discriminator\n    return model\ndiscriminator = get_dc_discriminator(input_shape)\ndiscriminator.summary()\ndisplay(visualkeras.layered_view(discriminator, legend=True, scale_xy=6))\ntfk.utils.plot_model(discriminator, show_shapes=True, expand_nested=True, to_file='vanilla_discriminator.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_dim = 256\nnum_classes= Y.max() + 1\ngenerator_in_channels = latent_dim + num_classes #we compute the one-hot encoding of the labels and we concatenate it batch level with the input of the generator (noise)\ndiscriminator_in_channels = num_channels + num_classes #we increase the number of channels of the images according to the number of classes\nprint(generator_in_channels, discriminator_in_channels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conditional_generator_input = (generator_in_channels)\nconditional_discriminator_input = (image_size, image_size, discriminator_in_channels)\nconditional_discriminator_input, conditional_generator_input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConditionalGAN(tfk.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(ConditionalGAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n        self.loss_tracker = tfk.metrics.Mean(name=\"loss\")\n        self.d_loss_tracker = tfk.metrics.Mean(name=\"d_loss\")\n        self.g_loss_tracker = tfk.metrics.Mean(name=\"g_loss\")\n\n    def compile(self, d_optimizer, g_optimizer):\n        super(ConditionalGAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n\n    @property\n    def metrics(self):\n        return [\n            self.loss_tracker,\n            self.d_loss_tracker,\n            self.g_loss_tracker\n        ]\n\n    @tf.function\n    def train_step(self, data):\n        real_images, one_hot_labels = data\n        batch_size = tf.shape(real_images)[0]\n        \n        image_one_hot_labels = one_hot_labels[:, :, None, None]\n        image_one_hot_labels = tf.repeat(image_one_hot_labels, repeats=[image_size * image_size])\n        image_one_hot_labels = tf.reshape(image_one_hot_labels, (-1, image_size, image_size, num_classes))\n        \n        # Sample random points in the latent space\n        z = tf.random.normal(shape=(batch_size, self.latent_dim))\n        z = tf.concat([z, one_hot_labels], -1)\n\n        # Generate fake images from z\n        generated_images = self.generator(z)\n\n        \n        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n        # Combine generated images and real ones\n        combined_images = tf.concat([fake_image_and_labels, real_image_and_labels], axis=0)\n\n        # Create labels so that fake images correspond to class 0 and real images to class 1\n        labels = tf.concat([tf.zeros((batch_size, 1)), tf.ones((batch_size, 1))], axis=0)\n\n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = tf.reduce_mean(tfk.losses.binary_crossentropy(labels, predictions))\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        loss = d_loss\n\n        # Sample random points in the latent space\n        z = tf.random.normal(shape=(batch_size, self.latent_dim))\n        z = tf.concat([z, one_hot_labels], axis=1)\n        \n        # Create misleading labels for fake images so that they correspond to class 1\n        misleading_labels = tf.ones((batch_size, 1))\n\n        # Train the generator \n        with tf.GradientTape() as tape:\n            print(z.shape)\n            fake_images = self.generator(z)\n            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n            misleading_predictions = self.discriminator(fake_image_and_labels)\n            g_loss = tf.reduce_mean(tfk.losses.binary_crossentropy(misleading_labels, misleading_predictions))\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        loss += g_loss\n\n        # Update metrics\n        self.loss_tracker.update_state(loss)\n        self.d_loss_tracker.update_state(d_loss)\n        self.g_loss_tracker.update_state(g_loss)\n        return {\n            \"loss\": self.loss_tracker.result(),\n            \"d_loss\": self.d_loss_tracker.result(),\n            \"g_loss\": self.g_loss_tracker.result(),\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConditionalGANMonitor(tfk.callbacks.Callback):\n    def __init__(self, num_img=10, latent_dim=latent_dim, name='', gray=False):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n        self.name = name\n        self.gray = gray\n\n    def on_epoch_end(self, epoch, logs=None):\n        tf.random.set_seed(seed)\n        os.makedirs(self.name+'temp', exist_ok=True)\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        labels = tf.cast(tf.math.floormod(tf.range(0,self.num_img), num_classes), 'float32')\n        labels = tfk.utils.to_categorical(labels, num_classes)\n        random_latent_vectors = tf.concat([random_latent_vectors,labels],-1)\n        generated_images = self.model.generator(random_latent_vectors).numpy()\n\n        fig, axes = plt.subplots(1, self.num_img, figsize=(20,2*self.num_img))\n        for i in range(self.num_img):\n            img = tfk.preprocessing.image.array_to_img(generated_images[i])\n            ax = axes[i%self.num_img]\n            if self.gray:\n                ax.imshow(np.squeeze(img), cmap='gray')\n            else:\n                ax.imshow(np.squeeze(img))\n            ax.axis('off')\n        fig.savefig(self.name+'temp/'+'{:0>5}'.format(epoch)+'.png') \n        plt.tight_layout()\n        plt.show()\n\n    def on_train_end(self, logs=None):\n        fp_in = self.name+\"temp/*.png\"\n        fp_out = self.name+\"_generated_images.gif\"\n        imgs = (Image.open(f) for f in sorted(glob.glob(fp_in)))\n        img = next(imgs)\n        img.save(fp=fp_out, format='GIF', append_images=imgs, save_all=True, duration=100, optimize=False)    \n        shutil.rmtree(self.name+\"temp\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nlearning_rate = 5e-5\nbatch_size = 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cgan = ConditionalGAN(\n    discriminator = get_dc_discriminator(conditional_discriminator_input), \n    generator = get_dc_generator(int(conditional_generator_input)), \n    latent_dim = latent_dim\n)\ncgan.compile(\n    d_optimizer = tfk.optimizers.Adam(learning_rate=learning_rate),\n    g_optimizer = tfk.optimizers.Adam(learning_rate=learning_rate)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_history = cgan.fit(\n    X, \n    epochs = epochs, \n    callbacks = [ConditionalGANMonitor(name='conditional', gray=True)],\n    verbose = 2\n).history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cgan.generator.save('conditional_gan_generator')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip './'","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}